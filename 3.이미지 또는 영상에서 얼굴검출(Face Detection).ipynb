{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haar feature 기반 cascade classifier(다단계분류)를 이용한 객채검출에 대해서 얼굴 검출을 위한 코드를 작성하려고 한다.\n",
    "\n",
    "Haar cascade classifier는 2001년 Paul Viola와 Micheal Jones의 논문인 'Rapid Object Detection using a Boossed Cascde of simple Feature'에서 제안된 효과적인 검출 방법이다.\n",
    "\n",
    "이방법은 다수의 객채이미지(positive)와 객체가 아닌 이미지(negative)를 cascade함수로 트레이닝 시켜 객체 검출을 달성하는 머신러닝 기반의 접근방법이다.\n",
    "\n",
    "먼저, 얼굴검출을 위해 많은 수의 얼굴 이미지와 얼굴이 없는 이미지를 classifier에 트레이닝 시켜 얼굴에 대한 특징들을 추출해서 데이터로 저장해 두어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "def faceDetect():\n",
    "    eye_detect = False\n",
    "    face_cascade = cv2.CascadeClassifier('datasets/haarcascade_frontface.xml')\n",
    "    eye_cascade = cv2.CascadeClassifier('datasets/haarcascade_eye.xml')\n",
    "    info = ''\n",
    "    \n",
    "    try:\n",
    "        cap = cv2.VideoCapture(0)# 비디오 킨다.\n",
    "    except:\n",
    "        print('카메라 로딩 실패')\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read() #비디오 데이터 불러오기\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if eye_detect:\n",
    "            info = 'Eye Detection On'\n",
    "        else:\n",
    "            info = 'Eye Detection Off'\n",
    "            \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        cv2.putText(frame, info, (5, 15), font, 0.5, (255,0,255), 1)\n",
    "        \n",
    "        for (x,y,w,h) in faces:    \n",
    "            cv2.rectangle(frame, (x,y),(x+w,y+h),(255, 0, 0), 2)\n",
    "            cv2.putText(frame, 'Detected Face',(x-5,y-5), font, 0.5, (255,255,0), 2)\n",
    "            if eye_detect:\n",
    "                roi_gray = gray[y:y+h, x:x+w]\n",
    "                roi_color = frame[y:y+h, x:x+w]\n",
    "                eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "                for (ex, ey, ew, eh) in eyes:\n",
    "                    cv.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh),(0, 255, 0), 2)\n",
    "                    \n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(30)\n",
    "        if k == ord('i'):\n",
    "            eye_edtect = not eye_detect\n",
    "        if k == 27:\n",
    "            break\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "faceDetect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - face_cascade = cv2.CascadeClassifier('datasets/haarcascade_frontface.xml')\n",
    " - eye_cascade = cv2.CascadeClassifier('datasets/haarcascade_eye.xml')\n",
    " \n",
    " 얼굴 검출과 눈 검출을 위한 Haar-Cascade 트레이닝 데이터를 각각 읽어 CascadeClassifier 객채를 생성합니다. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "detectMultiScale함수에 grayscale 이미지를 입력하여 얼굴을 검출합니다. 얼굴이 검출되면 위치를 리스트로 리턴합니다. 위치는 (x,y,w,h)와 같은 튜플이며 (x,y)는 검출된 얼굴의 좌상단 위치, w,h는 가로,세로크기 입니다.\n",
    "\n",
    "detectMultiScale()의 성분 1.3은 ScaleFactor, 5는 minNeighbor를 의미하는 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- roi_gray = gray[y:y+h, x:x+w]\n",
    "- roi_color = frame[y:y+h, x:x+w]\n",
    "- eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "사람눈을 검출하기 위해서 검출된 얼굴 영역에서 눈을 검출하는 것이다. 검출되면 그 위치를 리스트로 리턴합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지에서 얼굴 검출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "def faceDetect():\n",
    "    eye_detect = True\n",
    "    face_cascade = cv2.CascadeClassifier('datasets/haarcascade_frontface.xml')\n",
    "    eye_cascade = cv2.CascadeClassifier('datasets/haarcascade_eye.xml')\n",
    "    info = ''\n",
    "    \n",
    "    try:\n",
    "        imgfile = 'image/people3.jpg' #이미지가 저장되있는 디렉토리(현재 실행되는 디렉기준)\n",
    "        frame = cv2.imread(imgfile, cv2.IMREAD_COLOR) # 이미지 불러오기\n",
    "    except:\n",
    "        print('이미지 로딩 실패')\n",
    "        return\n",
    "            \n",
    "    if eye_detect:\n",
    "        info = 'Eye Detection On'\n",
    "    else:\n",
    "        info = 'Eye Detection Off'\n",
    "            \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)# 사진의 색깔 변환(cvtColor)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)#사진에서 검출한 좌표정보(x,y,w,h)\n",
    "        \n",
    "    cv2.putText(frame, info, (5, 15), font, 0.5, (255,0,255), 1)\n",
    "        \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x,y),(x+w,y+h),(255, 0, 0), 2)#frame에 사각형 모양 대입\n",
    "        cv2.putText(frame, 'Detected Face',(x-5,y-5), font, 0.5, (255,255,0), 2)\n",
    "        if eye_detect:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh),(0, 255, 0), 2)\n",
    "    \n",
    "    \n",
    "    cv2.namedWindow('frame',cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    k = cv2.waitKey(0) & 0xFF #키보드값을 아스키코드로 반환\n",
    "    if k ==27:     \n",
    "        cv2.destroyAllWindows()  \n",
    "    elif k == ord('c'):\n",
    "        cv2.imwrite('image/people3_copy.jpg',gray)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "faceDetect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 흑백사진으로 저장하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "얼굴 좌표: [[ 710  232   39   39]\n",
      " [ 358  248   42   42]\n",
      " [1020  257   42   42]\n",
      " [ 524  499   48   48]\n",
      " [ 737  514   45   45]\n",
      " [ 865  524   44   44]\n",
      " [ 984  536   47   47]\n",
      " [ 878  304   47   47]\n",
      " [ 753  317   40   40]\n",
      " [ 387  316   44   44]\n",
      " [1008  598   50   50]\n",
      " [ 319  179   46   46]\n",
      " [ 521  196   47   47]\n",
      " [ 975  204   43   43]\n",
      " [ 227  219   46   46]\n",
      " [ 604  220   47   47]\n",
      " [ 106  230   48   48]\n",
      " [ 910  227   48   48]\n",
      " [1123  234   49   49]\n",
      " [ 255  487   51   51]\n",
      " [ 137  501   52   52]\n",
      " [1276  266   50   50]\n",
      " [ 637  511   48   48]\n",
      " [ 378  514   49   49]\n",
      " [1127  525   54   54]\n",
      " [1090  311   52   52]\n",
      " [ 491  317   50   50]\n",
      " [ 979  321   49   49]\n",
      " [1287  557   52   52]\n",
      " [ 170  329   53   53]\n",
      " [ 503  569   52   52]\n",
      " [ 882  571   54   54]\n",
      " [ 628  576   51   51]\n",
      " [ 754  577   49   49]\n",
      " [ 163  183   47   47]\n",
      " [ 282  344   49   49]\n",
      " [ 231  581   49   49]\n",
      " [ 421  190   49   49]\n",
      " [ 642  190   47   47]\n",
      " [ 365  582   56   56]\n",
      " [1075  207   47   47]\n",
      " [1176  208   45   45]\n",
      " [1094  615   53   53]\n",
      " [1224  634   53   53]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "def faceDetect():\n",
    "    eye_detect = True\n",
    "    face_cascade = cv2.CascadeClassifier('datasets/haarcascade_frontface.xml')\n",
    "    eye_cascade = cv2.CascadeClassifier('datasets/haarcascade_eye.xml')\n",
    "    info = ''\n",
    "    \n",
    "    try:\n",
    "        imgfile = 'image/people3.jpg' #이미지 저장 디렉토리\n",
    "        frame = cv2.imread(imgfile, cv2.IMREAD_COLOR) # 이미지 불러오기\n",
    "    except:\n",
    "        print('이미지 로딩 실패')\n",
    "        return\n",
    "            \n",
    "    if eye_detect:\n",
    "        info = 'Eye Detection On'\n",
    "    else:\n",
    "        info = 'Eye Detection Off'\n",
    "            \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "    cv2.putText(frame, info, (5, 15), font, 0.5, (255,0,255), 1)\n",
    "        \n",
    "    for (x,y,w,h) in faces:    \n",
    "        cv2.rectangle(gray, (x,y),(x+w,y+h),(255, 0, 0), 2)\n",
    "        cv2.putText(gray, 'Detected Face',(x-5,y-5), font, 0.5, (255,255,0), 2)\n",
    "        if eye_detect:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh),(0, 255, 0), 2)\n",
    "    \n",
    "    print('얼굴 좌표:',faces)\n",
    "    cv2.namedWindow('gray',cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('gray', gray)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "    if k ==27:     \n",
    "        cv2.destroyAllWindows()  \n",
    "    elif k == ord('c'):\n",
    "        cv2.imwrite('image/people3_copy_g.jpg',gray)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "faceDetect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
