{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 픽셀 값 얻고 수정하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한장의 의미지는 지정된 크기의 BGR 값들의 배열이다. 각 픽셀들은 (B,G,R)값을 가지고 있고 이 숫자는 0~255 사이의 정수가 된다. img = cv.imread()는 이미지를 읽은 후 Numpy array 형식으로 img에 담는다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 62 107 158]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image/lena.jpg')\n",
    "px = img[50,50]\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드는 image/lena.jpg파일을 읽어서 (50,50)위치의 픽셀값을 출력하는 코드이다. 출력값에 해당하는 것이 (B,G,R)이다. 만약이 이 픽샐의 값을 변경하고싶다면 img[50,50] = [0,0] 이라고 하면 된다. 또는 [50,50,0],[50,50,1],[50,50,2]로 각각 개인의 값을 변경하는 것도 가능하다. 그러나 작업상 문제가 생길 수 있다. 그래서 Numpy의 계산인 img.item()을 사용하는 것이 더 좋다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62, 107, 158]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image/lena.jpg')\n",
    "\n",
    "B = img.item(50,50,0) #img.itemset((50,50,0),100)\n",
    "G = img.item(50,50,1)\n",
    "R = img.item(50,50,2)\n",
    "\n",
    "BGR = [B,G,R]\n",
    "print(BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 속성 얻기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 속성을 얻기 위해서 Numpy를 사용한다.\n",
    "- img.shape : 이미지 해상도 및 컬러채널(이미지 height, 이미지 width, 컬러채널수)\n",
    "- img.size : 이미지 사이즈(바이트)\n",
    "- img.dtype : 이미지 데이터 타입."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "786432\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image/lenna.png')\n",
    "\n",
    "print(img.shape)\n",
    "print(img.size)\n",
    "print(img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 ROI설정 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 처리할 때, 이미지의 특정 영역에서 작업이 이루어질 경우가 있다. 예를 들어서 이미지에서 눈을 찾는 경우 이미지 전체에서 얼굴을 먼저 찾은 뒤 이 얼굴 영역에서 눈을 찾는 것이 성능면에서 효율적이다. \n",
    "\n",
    "ROI(Region Of Image)는 Numpy 인덱싱을 통해서 얻을 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "(100, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image/lenna.png')\n",
    "cv2.imshow('original',img)\n",
    "\n",
    "subimg = img[200:300, 100:500] #img[x:x+w, y:y+h]\n",
    "cv2.imshow('chtting',subimg)\n",
    "\n",
    "img[300:400, 0:400] = subimg\n",
    "\n",
    "print(img.shape)\n",
    "print(subimg.shape)\n",
    "\n",
    "cv2.imshow('modified', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 채널 분할 및 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 78  68 178]\n",
      "78 68 178\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image/lenna.png')\n",
    "\n",
    "b, g, r = cv2.split(img)# BGR채널로 분리\n",
    "\n",
    "print(img[100,100])\n",
    "print(b[100,100],g[100,100],r[100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('image/lenna.png')\n",
    "\n",
    "b, g, r = cv2.split(img)# BGR채널로 분리\n",
    "\n",
    "cv2.imshow('blue channel', b)\n",
    "cv2.imshow('green channel', g)\n",
    "cv2.imshow('red channel', r)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "marge_img = cv2.merge((b,g,r))\n",
    "cv2.imshow('merged',merge_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴 사진 잘라내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "def faceDetect():\n",
    "    eye_detect = True\n",
    "    face_cascade = cv2.CascadeClassifier('datasets/haarcascade_frontface.xml')\n",
    "    eye_cascade = cv2.CascadeClassifier('datasets/haarcascade_eye.xml')\n",
    "    info = ''\n",
    "    \n",
    "    try:\n",
    "        imgfile = 'image/people3.jpg' #이미지 저장 디렉토리\n",
    "        frame = cv2.imread(imgfile, cv2.IMREAD_COLOR) # 이미지 불러오기\n",
    "    except:\n",
    "        print('이미지 로딩 실패')\n",
    "        return\n",
    "            \n",
    "    if eye_detect:\n",
    "        info = 'Eye Detection On'\n",
    "    else:\n",
    "        info = 'Eye Detection Off'\n",
    "            \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    cv2.putText(frame, info, (5, 15), font, 0.5, (255,0,255), 1)\n",
    "    \n",
    "    face_number, xywh = faces.shape\n",
    "    sub_img = {}\n",
    "\n",
    "    \n",
    "    for i in range(face_number):\n",
    "        x, y, w, h = faces[i]\n",
    "        sub_img[i] = gray[y:y+w,x:x+h] \n",
    "        cv2.imshow('face%s'%i,sub_img[i])      \n",
    "        \n",
    "\n",
    "    cv2.namedWindow('gray',cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('gray', gray)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "    if k ==27:  #ESC\n",
    "        cv2.destroyAllWindows()  \n",
    "    elif k == ord('c'):\n",
    "        cv2.imwrite('image/people3_copy_g.jpg',gray)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "faceDetect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
